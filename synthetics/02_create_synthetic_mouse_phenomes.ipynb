{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTRxpSlaczHY"
   },
   "source": [
    "# Create synthetic mouse phenome data\n",
    "\n",
    "Create a synthetic version of the mouse phenomes from the original experiment, which are available after running `01_create_phenome_training_data.ipynb`. To run this notebook, you will need an API key from the Gretel console,  at https://console.gretel.cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEM6kjRsczHd"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ-TmAdwczHd"
   },
   "outputs": [],
   "source": [
    "# Specify your Gretel API key\n",
    "\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "from gretel_client import configure_session, ClientConfig\n",
    "\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "configure_session(ClientConfig(api_key=getpass(prompt=\"Enter Gretel API key\"), \n",
    "                               endpoint=\"https://api.gretel.cloud\"))\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmHDICI1oPS5"
   },
   "outputs": [],
   "source": [
    "# Create a project\n",
    "\n",
    "from gretel_client import create_project\n",
    "\n",
    "project = create_project(display_name=\"synthetic-mouse-phenomes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PD5B0U06ALs"
   },
   "source": [
    "## Configure model hyper parameters\n",
    "Load the default configuration template. This template will work well for most datasets. View other templates at https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIu3hkzoCzGz"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from smart_open import open\n",
    "import yaml\n",
    "\n",
    "with open(\"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/config_templates/gretel/synthetics/default.yml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "# Optimize parameters for complex dataset\n",
    "config['models'][0]['synthetics']['params']['epochs'] = 150\n",
    "config['models'][0]['synthetics']['params']['vocab_size'] = 0\n",
    "config['models'][0]['synthetics']['params']['rnn_units'] = 1024\n",
    "config['models'][0]['synthetics']['params']['reset_states'] = False\n",
    "config['models'][0]['synthetics']['params']['learning_rate'] = 0.001\n",
    "\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9LTh7GO6VIu"
   },
   "source": [
    "## Load and preview the training dataset\n",
    "Specify a data source to train the model on. This can be a local file, web location, or HDFS file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMg9nX6SczHe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "base_path = pathlib.Path(os.getcwd().replace(\"/synthetics\", \"\"))\n",
    "data_path = base_path / 'mice_data_set' / 'data'\n",
    "dataset_path = data_path / 'phenomes_batch_0.csv'\n",
    "    \n",
    "df = pd.read_csv(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxnH8th-65Dh"
   },
   "source": [
    "## Train the synthetic model\n",
    "In this step, we will task the worker running in the Gretel cloud, or locally, to train a synthetic model on the source dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4-E_F0qczHe"
   },
   "outputs": [],
   "source": [
    "from gretel_client.helpers import poll\n",
    "\n",
    "config['models'][0]['synthetics']['generate']['num_records'] = len(df)\n",
    "model = project.create_model_obj(model_config=config)\n",
    "model.data_source = str(dataset_path)\n",
    "model.submit(upload_data_source=True)\n",
    "\n",
    "poll(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bgWKArX7QGf"
   },
   "source": [
    "# Save the synthetically generated phenomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPM-gaU6czHf"
   },
   "outputs": [],
   "source": [
    "# View the synthetic data\n",
    "\n",
    "synthetic_phenomes = pd.read_csv(model.get_artifact_link(\"data_preview\"), compression='gzip')\n",
    "synthetic_phenomes.to_csv(data_path / 'synthetic_phenomes_batch_0.csv', index=False)\n",
    "synthetic_phenomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69XYfU9k7fq4"
   },
   "source": [
    "# View the synthetic data quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zX8qsizqczHg",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate report that shows the statistical performance between the training and synthetic data\n",
    "\n",
    "import IPython\n",
    "from smart_open import open\n",
    "\n",
    "IPython.display.HTML(data=open(model.get_artifact_link(\"report\")).read())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Create synthetic data from a DataFrame or CSV",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

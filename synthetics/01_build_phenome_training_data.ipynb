{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group phenotypes and covariates into functional batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/redlined/anaconda3/envs/genomics/lib/python3.9/site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /home/redlined/anaconda3/envs/genomics/lib/python3.9/site-packages (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/redlined/anaconda3/envs/genomics/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/redlined/anaconda3/envs/genomics/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/redlined/anaconda3/envs/genomics/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -U pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUSCLE AND BONE TRAITS AND COVARIATES\n",
    "# ----------------------\n",
    "# For all five muscle weights (TA, EDL, soleus, plantaris and\n",
    "# gastrocnemius), we map QTLs conditioning on tibia length\n",
    "# (\"tibia\"). For tibia length, we map QTLs conditioned on body weight.\n",
    "#\n",
    "# Tibia length explains 12-18% of variance in the muscle weights. The\n",
    "# rationale for including tibia length as a covariate is bone length\n",
    "# may somehow regulate muscle weight as well, and we would like to\n",
    "# isolate the genetic factors that directly regulate development of\n",
    "# the muscle tissues.\n",
    "#  \n",
    "# For bone-mineral density (BMD), we created a binary trait that\n",
    "# signals \"abnormal\" BMD. We do not include any covariates when\n",
    "# mapping QTLs for these traits. Note that body weight is also\n",
    "# uncorrelated with BMD.\n",
    "# \n",
    "# For all muscle and bone traits, we include a binary indicator for\n",
    "# round SW16 as a covariate because the mice from this round showed\n",
    "# substantial deviation in these traits compared to the rest of the\n",
    "# mice.\n",
    "bone_muscle_pheno = [\n",
    "    'TA',\n",
    "    'SW16',\n",
    "    'tibia',\n",
    "    'EDL',\n",
    "    'soleua',\n",
    "    'plantaris',\n",
    "    'gastroc',\n",
    "    'SW6',\n",
    "    'sacweight',\n",
    "    'BMD',\n",
    "    'abBMD']\n",
    "\n",
    "# OTHER PHYSIOLOGICAL TRAITS AND COVARIATES\n",
    "# --------------------------\n",
    "# Body weights bw1, bw2 and bw3 were measured on subsequent days of\n",
    "# the methamphetamine sensitivity tests, and are highly correlated\n",
    "# with each other (r^2 = 98%), so it is only necessary to map QTLs for\n",
    "# one of them. The body weight measurements after sacrifice\n",
    "# (\"sacweight\") show a considerable departure in Round SW17, so we\n",
    "# include a binary indicator for this round as a covariate for\n",
    "# sacweight. We include age as a covariate for the \"bw0\" body weight\n",
    "# because it was measured while the mouse was still growing.\n",
    "#\n",
    "# Fasting glucose levels are explained partially by body weight (PVE =\n",
    "# 6%), so we include body weight as a covariate for fasting glucose\n",
    "# levels. Rounds SW1 and SW11 showed a considerable departure in\n",
    "# fasting glucose levels from the other rounds, so we included binary\n",
    "# indicators for these two rounds as covariates for fasting glucose\n",
    "# levels.\n",
    "other_physio_traits_pheno = [\n",
    "    'bw0',\n",
    "    'glucoseage',\n",
    "    'bw1',\n",
    "    'methage',\n",
    "    'SW17',\n",
    "    'PPIweight',\n",
    "    'sacweight',\n",
    "    'fastglucose',\n",
    "    'SW1',\n",
    "    'SW11',\n",
    "    'taillength',\n",
    "    'SW3',\n",
    "    'SW4',\n",
    "    'SW19',\n",
    "    'SW20',\n",
    "    'SW22',\n",
    "    'SW24',\n",
    "    'testisweight']\n",
    "\n",
    "# FEAR CONDITIONING TRAITS AND COVARIATES\n",
    "# ------------------------\n",
    "# For all fear conditioning traits, the cage used for testing appears\n",
    "# to have an effect on the phenotype, so we include binary indicators\n",
    "# for cage as covariates for all FC phenotypes. Further, the FC\n",
    "# phenotype measurements in Round SW17 show a noticeably different\n",
    "# distribution in the FC phenotypes from the other rounds, so we\n",
    "# include a binary indicator for round SW17 as a covariate in all FC\n",
    "# traits.\n",
    "#\n",
    "# These analyses control for proportion of freezing on day 1 during\n",
    "# exposure to the tone (\"AvToneD1\"). AvToneD1 explains 11-25% of the\n",
    "# variance in the Day 2 and Day 3 freezing measures. Note that here we\n",
    "# can map QTLs for freezing to the altered context on Day 3\n",
    "# (\"AvAltContextD3\") as a quantitative trait after conditioning on\n",
    "# AvToneD1 because the distribution for this trait is no longer quite\n",
    "# so bimodal, and looks fairly \"normal\". So there is no need to map\n",
    "# QTLs for the binary version of this trait.\n",
    "#\n",
    "# PreTrainD1 is a very ugly trait with massive box effects and a lot\n",
    "# of low values, which might have to be removed as outliers. It is\n",
    "# quite likely that these outliers represent the \"deaf\" mice that\n",
    "# might be skewing the whole results. These outliers are present in\n",
    "# every box, so not a box-specific effect.\n",
    "fear_cond_traits_pheno = [\n",
    "    'AVContextD2',\n",
    "    'AVToneD1',\n",
    "    'FCbox1',\n",
    "    'FCbox2',\n",
    "    'FCbox3',\n",
    "    'SW17',\n",
    "    'AVAltContextD3',\n",
    "    'AvToneD3',\n",
    "    'PreTrainD1',\n",
    "    'SW10',\n",
    "    'SW16',\n",
    "    'SW20',\n",
    "    'SW7',\n",
    "    'SW14']\n",
    "\n",
    "# METHAMPHETAMINE SENSITIVITY, LOCOMOTOR ACTIVITY AND ANXIETY-LIKE BEHAVIOR AND COVARIATES\n",
    "# -------------------------------------------------------------------------\n",
    "# We checked all the cages used in these tests to see whether the\n",
    "# phenotypes measured using any given cage departed noticeably from\n",
    "# the other cages. Cage #7 consistently has a large effect.\n",
    "meth_loco_anxiety_pheno1 = [\n",
    "    'D1totaldist0to15',\n",
    "    'D1totaldist0to30',\n",
    "    'D1TODIST5',\n",
    "    'D1TODIST10',\n",
    "    'D1TODIST15',\n",
    "    'D1TODIST20',\n",
    "    'D1TODIST25',\n",
    "    'D1TODIST30',\n",
    "    'D1ctrtime0to15',\n",
    "    'D1ctrtime0to30',\n",
    "    'D1hact0to15',\n",
    "    'D1hact0to30',\n",
    "    'D1vact0to15',\n",
    "    'D1vact0to30',\n",
    "    'methcage7',\n",
    "    'methcage8',\n",
    "    'methcage9',\n",
    "    'methcage10',\n",
    "    'methcage11',\n",
    "    'methcage12']\n",
    "\n",
    "meth_loco_anxiety_pheno2 = [\n",
    "    'D2totaldist0to15',\n",
    "    'D2totaldist0to30',\n",
    "    'D2TODIST5',\n",
    "    'D2TODIST10',\n",
    "    'D2TODIST15',\n",
    "    'D2TODIST20',\n",
    "    'D2TODIST25',\n",
    "    'D2TODIST30',\n",
    "    'D2ctrtime0to15',\n",
    "    'D2ctrtime0to30',\n",
    "    'D2hact0to15',\n",
    "    'D2hact0to30',\n",
    "    'D2vact0to15',\n",
    "    'D2vact0to30',\n",
    "    'methcage7',\n",
    "    'methcage8',\n",
    "    'methcage9',\n",
    "    'methcage10',\n",
    "    'methcage11',\n",
    "    'methcage12']\n",
    "\n",
    " \n",
    "\n",
    "meth_loco_anxiety_pheno3 = [\n",
    "    'D3totaldist0to15',\n",
    "    'D3totaldist0to30',\n",
    "    'D3TODIST5',\n",
    "    'D3TODIST10',\n",
    "    'D3TODIST15',\n",
    "    'D3TODIST20',\n",
    "    'D3TODIST25',\n",
    "    'D3TODIST30',\n",
    "    'D3ctrtime0to15',\n",
    "    'D3ctrtime0to30',\n",
    "    'D3hact0to15',\n",
    "    'D3hact0to30',\n",
    "    'D3vact0to15',\n",
    "    'D3vact0to30',\n",
    "    'methcage7',\n",
    "    'methcage8',\n",
    "    'methcage9',\n",
    "    'methcage10',\n",
    "    'methcage11',\n",
    "    'methcage12']\n",
    "\n",
    "# PREPULSE INHIBITION (PPI) PHENOTYPES AND COVARIATES\n",
    "# ------------------------------------\n",
    "# All boxes appear to have some effect on some of the PPI phenotypes,\n",
    "# with Box #3 having a particularly large effect on some phenotypes,\n",
    "# so we include all PPI box indicators as covariates in analysis of the\n",
    "# PPI phenotypes.\n",
    "#\n",
    "# We also map QTLs for habituation to pulses by analyzing the startle\n",
    "# response during the fourth block of pulse-alone trials against the\n",
    "# startle response during the first block of pulse-alone trials.\n",
    "ppi_pheno = [\n",
    "    'pp3PPIavg',\n",
    "    'pp6PPIavg',\n",
    "    'pp12PPIavg',\n",
    "    'PPIavg',\n",
    "    'startle',\n",
    "    'p120b4',\n",
    "    'PPIbox1',\n",
    "    'PPIbox2',\n",
    "    'PPIbox3',\n",
    "    'PPIbox4',\n",
    "    'p120b1']\n",
    "\n",
    "\n",
    "pheno_batches = [bone_muscle_pheno, other_physio_traits_pheno, fear_cond_traits_pheno, meth_loco_anxiety_pheno1, \n",
    "                 meth_loco_anxiety_pheno2, meth_loco_anxiety_pheno3, ppi_pheno]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "base_path = pathlib.Path(os.getcwd().replace(\"/synthetics\", \"\"))\n",
    "data_path = base_path / 'mice_data_set' / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>round</th>\n",
       "      <th>cageid</th>\n",
       "      <th>FCbox</th>\n",
       "      <th>PPIbox</th>\n",
       "      <th>methcage</th>\n",
       "      <th>methcycle</th>\n",
       "      <th>discard</th>\n",
       "      <th>mixup</th>\n",
       "      <th>earpunch</th>\n",
       "      <th>...</th>\n",
       "      <th>SW16</th>\n",
       "      <th>SW17</th>\n",
       "      <th>SW18</th>\n",
       "      <th>SW19</th>\n",
       "      <th>SW20</th>\n",
       "      <th>SW21</th>\n",
       "      <th>SW22</th>\n",
       "      <th>SW23</th>\n",
       "      <th>SW24</th>\n",
       "      <th>SW25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26305</td>\n",
       "      <td>SW18</td>\n",
       "      <td>1330002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26306</td>\n",
       "      <td>SW18</td>\n",
       "      <td>1330002.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26307</td>\n",
       "      <td>SW18</td>\n",
       "      <td>1330002.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26308</td>\n",
       "      <td>SW18</td>\n",
       "      <td>1330002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26309</td>\n",
       "      <td>SW18</td>\n",
       "      <td>1330003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>R</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id round     cageid  FCbox  PPIbox  methcage  methcycle discard mixup  \\\n",
       "1  26305  SW18  1330002.0    1.0     1.0       1.0        1.0      no    no   \n",
       "2  26306  SW18  1330002.0    2.0     3.0       2.0        1.0      no    no   \n",
       "3  26307  SW18  1330002.0    3.0     4.0       3.0        1.0      no    no   \n",
       "4  26308  SW18  1330002.0    4.0     5.0       4.0        1.0      no    no   \n",
       "5  26309  SW18  1330003.0    1.0     1.0       5.0        1.0      no    no   \n",
       "\n",
       "  earpunch  ...  SW16  SW17  SW18  SW19  SW20  SW21  SW22  SW23  SW24  SW25  \n",
       "1        R  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2        R  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3        L  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4        L  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5        R  ...   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the pheno data saved from map notebook and discard lines with no data\n",
    "\n",
    "import pandas as pd\n",
    "phenofile = data_path / \"pheno_new.csv\"\n",
    "pheno_data = pd.read_csv(phenofile)\n",
    "pheno_data = pheno_data[pheno_data[\"cageid\"].notnull()]\n",
    "pheno_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic training files for each phenome batch. Create one with \"id\" for joining with the genome\n",
    "# data, and one without \"id\" for phenome training\n",
    "\n",
    "for i in range(len(pheno_batches)):\n",
    "    columns_use = pheno_batches[i]\n",
    "    columns_use.append(\"id\")\n",
    "    pheno_batch = pheno_data.filter(columns_use) \n",
    "    pheno_batch.dropna(inplace=True)\n",
    "    pheno_batch = pheno_batch.round(2)\n",
    "    pheno_batch_file = \"pheno_batch\" + str(i) + \"_withID.csv\"\n",
    "    filename = data_path / pheno_batch_file\n",
    "    pheno_batch.to_csv(filename, header=True, index=False)\n",
    "    pheno_batch = pheno_batch.drop(['id'], axis=1)\n",
    "    pheno_batch_file = \"pheno_batch\" + str(i) + \".csv\"\n",
    "    filename = data_path / pheno_batch_file\n",
    "    pheno_batch.to_csv(filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one big phenome dataset using all the relevant columns\n",
    "\n",
    "columns_use = []\n",
    "for next_batch in pheno_batches:\n",
    "    columns_use = columns_use + next_batch\n",
    "    \n",
    "# Remove duplicates\n",
    "columns_uniq = list(set(columns_use))\n",
    "\n",
    "# Filter down to just these columns\n",
    "pheno_alldata = pheno_data.filter(columns_uniq)\n",
    "\n",
    "# Save data out for later comparison with synthetic data\n",
    "phenofile = data_path / \"phenome_alldata.csv\"\n",
    "pheno_alldata.to_csv(phenofile, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
